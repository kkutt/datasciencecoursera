---
title       : Training/test proportion and decision tree accuracy
subtitle    : Developing Data Products
author      : Rubik
job         : 
framework   : io2012        # {io2012, html5slides, shower, dzslides, ...}
highlighter : highlight.js  # {highlight.js, prettify, highlight}
hitheme     : tomorrow      # 
widgets     : []            # {mathjax, quiz, bootstrap}
mode        : selfcontained # {standalone, draft}
knit        : slidify::knit2slides
---

## Problem assesed in my application

How data partition proportion influences machine learning algorithm accuracy?

--- 

## Method

1. Iris dataset is loaded
2. User can select how many cases from dataset go to training set (others go to testing set)
3. Simple decision tree model is trained on training dataset
4. Model is evaluated on testing dataset
5. Accuracy is presented to user

--- 

## Sample of results presented in application

In my application user can see how trained decision tree looks like, e.g.:

```{r echo=FALSE}
library(datasets)
library(caret)
library(e1071)
data(iris)

inTrain <- createDataPartition(y=iris$Species, p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
modFit <- train(Species ~ .,method="rpart",data=training)
print(modFit$finalModel)
```

__NOTE__: This decision tree was created during slidifying the presentation.

--- 

## Thank you for your attention!

